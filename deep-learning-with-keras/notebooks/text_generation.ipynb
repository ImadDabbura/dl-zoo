{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils import get_file\n",
    "from keras import models, optimizers\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the corpus is: 600893\n"
     ]
    }
   ],
   "source": [
    "# Get the text file\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "\n",
    "with open(path) as f:\n",
    "    text = f.read().lower()\n",
    "print(f\"The length of the corpus is: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences is: 200278\n",
      "Number of unique characters is: 57\n",
      "Feature shape: (200278, 60, 57); Target shape: (200278, 57)\n"
     ]
    }
   ],
   "source": [
    "# Length of the extracted character sequences\n",
    "max_len = 60\n",
    "\n",
    "# Sample sequences every `step` characters\n",
    "step = 3\n",
    "\n",
    "# Hold extracted sequences\n",
    "sequences = []\n",
    "\n",
    "# Hold target of extracted sequences (i.e. next character)\n",
    "next_chars = []\n",
    "\n",
    "# Iterate over corpus to extract sequences and next charater\n",
    "# for each sequeence every `step` characters\n",
    "for i in range(0, len(text) - max_len, step):\n",
    "    sequences.append(text[i:i + max_len])\n",
    "    next_chars.append(text[i + max_len])\n",
    "print(f'Number of sequences is: {len(sequences)}')\n",
    "\n",
    "# Extract the unique character from text and sort them\n",
    "chars = sorted(list(set(text)))\n",
    "print(f'Number of unique characters is: {len(chars)}')\n",
    "\n",
    "# Define a char_indices dictionary that maps each unique character to its index\n",
    "char_indices = {char:chars.index(char) for char in chars}\n",
    "\n",
    "# One-hot encode characters into arrays\n",
    "X = np.zeros((len(sequences), max_len, len(chars)))\n",
    "y = np.zeros((len(sequences), len(chars)))\n",
    "for i, sentence in enumerate(sequences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "    \n",
    "print(f'Feature shape: {X.shape}; Target shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = models.Sequential()\n",
    "model.add(LSTM(128, input_shape=(max_len, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "model.compile(optimizer=optimizers.rmsprop(lr=0.01),\n",
    "              loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling method that reweighting distribution of\n",
    "# softmax output based on temperature\n",
    "def sample(preds, temperature):\n",
    "    preds = np.asarray(preds, 'float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    preds = np.exp(preds)\n",
    "    # Normalize pred\n",
    "    probs = preds / np.sum(preds)\n",
    "    out = np.random.multinomial(1, probs, 1)\n",
    "    return np.argmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 123s 614us/step - loss: 1.6414\n",
      "----- Generated with seed:\n",
      ". fear and sympathy it is with these feelings that man has\n",
      "h\n",
      "----- Temperature used is : 0.2\n",
      ". fear and sympathy it is with these feelings that man has\n",
      "have and some of the state and the state the strither and the stright of the man and all the state of the man the better the present and successed and one and in the states that the same in the same and some of the states has and man and an all the present that the same and respect that the man in the strith the same that the present and are something and some of the same in the subject of the pres\n",
      "----- Temperature used is : 0.5\n",
      "re something and some of the same in the subject of the present of the love,\n",
      "and there all itself a successes of the more realong of the general existence that is the same and the germans that which when the present all that which is not be germans and the general consequently habed and some near of the something have and degnesting mankind not as a state and all that the interes of modern that the substine is in revealing and of which conduct that it is t\n",
      "----- Temperature used is : 1\n",
      "e substine is in revealing and of which conduct that it is the examity. to by nake as relations, but begain, that\n",
      "on that the consequers hen lessure;\n",
      "his. they thought deelf an astes the\n",
      "\"grathe \"wandly\n",
      "skncine consequently--there ahough socced it canass, what\n",
      "his remaining--ulight is rimuls age\n",
      "diselfest--on mankind for homes werm man? yot when therefee what\n",
      "nothing of morality not os himself, \"whear mode called that\n",
      "exterration,\n",
      "as that it is more, whoer\n",
      "----- Temperature used is : 1.2\n",
      "hear mode called that\n",
      "exterration,\n",
      "as that it is more, whoere heres that, with every greatests, theveffacfys whatome hourter, anciowan commagesly;\"\n",
      "unounser atreant;\n",
      "never of evil hereby ledste.\n",
      "\n",
      " 30x when when solit.\n",
      "shooness, as\n",
      "dislicated inidivedooncianance men. possesijed has eerstocless; thating--xumelt\n",
      "fommernoous,\n",
      "-ngat\n",
      "sencourisy. the welsequre but its last of the thinepwaves origen that regard\n",
      "the mamely \n",
      "treredir, alrequured, as at when the he w\n",
      "epoch : 1\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 126s 629us/step - loss: 1.5516\n",
      "----- Generated with seed:\n",
      "sly pit below?--\n",
      "     my realm--what realm hath wider bounda\n",
      "----- Temperature used is : 0.2\n",
      "sly pit below?--\n",
      "     my realm--what realm hath wider boundar of the conscience and still sension of the can and subject the spiritual and and and the consequent of the conscience and sension of the case and and the cances and conscience of the consequent of the same the conscience of the will and canner and cause the discompreting and spiritual and cances and consequent and and soul and carrined and conception of the struction of any of the morality of th\n",
      "----- Temperature used is : 0.5\n",
      "and conception of the struction of any of the morality of the history of the dangerous and\n",
      "sanction and and conscience of existence of the presented of the sensiment the the right of the man the case and and acception of world and desire is and concession and forms and discrust still discomprementance and sours of the will of the consicunation of desures of references, and german without precipile, and be the opprision of the abst, and the the offer in the\n",
      "----- Temperature used is : 1\n",
      ", and be the opprision of the abst, and the the offer in the desthulity: in most, sisuand right\n",
      "he has be truth, general can only,andority.\n",
      "\n",
      "beonginal discomncious of indichers; to the piceismencaveness\n",
      "of oppression of\n",
      "the\n",
      "simalial\n",
      "meetering of consciences,\n",
      "without as light almost, presented of\n",
      "anyus oneks ourmer herfried of \"france, acts if present decidiuts aiolice and in who are consingunties in hord\n",
      "and may incitured thus predanded wever too the eestl\n",
      "----- Temperature used is : 1.2\n",
      "in hord\n",
      "and may incitured thus predanded wever too the eestluas nger, and sourseit\n",
      "onuses. themselves.\n",
      "an ancranms of renound pueant tet, that formst, in    been with temetthne forculty, demand, the ethowed has ne orfusuanca, notmaces.\n",
      "\n",
      "tho xembigited inite, as sroffencess and grading or xiflencibiborile. soor would nowledgriccwing\n",
      "cieduchled a\n",
      "rtempe has not on\n",
      "mis\"\" setradity: thens, humanisy which learnn, that domand\n",
      "with efficu a\n",
      "longer sknies: he wime\n"
     ]
    }
   ],
   "source": [
    "# Iterate over num_epochs to train the model\n",
    "for epoch in range(2):\n",
    "    # Fit the model one epoch at a time\n",
    "    print(f'epoch : {epoch}')\n",
    "    model.fit(X, y, batch_size=128, epochs=1)\n",
    "    \n",
    "    # Select text seed at random\n",
    "    start_index = np.random.randint(0, len(text) - max_len - 1)\n",
    "    generated_text = text[start_index:start_index + max_len]\n",
    "    print(f'----- Generated with seed:\\n{generated_text}')\n",
    "    \n",
    "    # Iterate over different values of softmax temperatures\n",
    "    for temperature in [0.2, 0.5, 1, 1.2]:\n",
    "        print(f'----- Temperature used is : {temperature}')\n",
    "        sys.stdout.write(generated_text)\n",
    "        # Generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, max_len, len(chars)))\n",
    "            \n",
    "            # One-hot encode randomly generated text\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1\n",
    "            \n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "            \n",
    "            sys.stdout.write(next_char)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
