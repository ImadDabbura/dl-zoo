{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import layers, models\n",
    "from keras.datasets import imdb, mnist\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 10000), (25000, 10000))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a fn that applies one-hot encoding\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    \"\"\"\n",
    "    Applies one-hot encoding on sequences.\n",
    "    \"\"\"\n",
    "    resuls = np.zeros((len(sequences), dimension))\n",
    "    \n",
    "    for i, sequence in enumerate(sequences):\n",
    "        resuls[i, sequence] = 1\n",
    "        \n",
    "    return resuls\n",
    "\n",
    "# Convert sequences into one-hot encoding vectors\n",
    "X_train = vectorize_sequences(X_train)\n",
    "X_test = vectorize_sequences(X_test)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.3901 - acc: 0.8413\n"
     ]
    }
   ],
   "source": [
    "# Building fully connected NN using Sequential model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation=\"relu\", input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 0.3865 - acc: 0.8514\n"
     ]
    }
   ],
   "source": [
    "# Building fully connected NN using functional API\n",
    "input_tensor = layers.Input(shape=(10000,))\n",
    "x = layers.Dense(16, activation=\"relu\")(input_tensor)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "output_tensor = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = models.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multi-input model\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_size = 500\n",
    "\n",
    "# Create text related input layers\n",
    "text_input = layers.Input(shape=(10000,), dtype=\"int32\", name=\"text\")\n",
    "embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "# Create question related layers\n",
    "question_input = layers.Input(shape=(10000,), dtype=\"int32\", name=\"question\")\n",
    "embedded_question = layers.Embedding(64, question_vocabulary_size)(question_input)\n",
    "encoded_question = layers.LSTM(32)(question_text)\n",
    "\n",
    "# Concatenate both inputs\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question])\n",
    "\n",
    "# Build dense layer\n",
    "answer = layers.Dense(answer_size, activation=\"softmax\")(concatenated)\n",
    "\n",
    "# Compile the model\n",
    "answer.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "# Fit the model either using dictionary or list\n",
    "history = model.fit([text, question],\n",
    "                    answers,\n",
    "                    batch_size=256,\n",
    "                    epochs=1)\n",
    "\n",
    "history = model.fit({\"text\": text, \"question\": question},\n",
    "                    answers,\n",
    "                    batch_size=256,\n",
    "                    epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create multi-output model using social media posts\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = layers.Input(shape=(None,), dtype=\"int32\", name=\"posts\")\n",
    "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_posts)\n",
    "x = layers.MaxPool1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation=\"relu\")(x)\n",
    "x = layers.Conv1D(256, 5, activation=\"relu\")(x)\n",
    "x = layers.MaxPool1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation=\"relu\")(x)\n",
    "x = layers.Conv1D(256, 5, activation=\"relu\")(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "age_predictions = layers.Dense(1, name=\"age\")(x)\n",
    "income_predictions = layers.Dense(num_income_groups, activation=\"softmax\", name=\"income\")(x)\n",
    "gender_predictions = layers.Dense(1, activation=\"sigmoid\", name=\"gender\")(x)\n",
    "\n",
    "model = models.Model(posts_input, [age_predictions, income_predictions, gender_predictions])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mse\", \"categorical_crossentropy\", \"binary_crossentropy\"],\n",
    "              loss_weights=[0.25, 1, 10])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"age\": \"mse\", \"income\": \"categorical_crossentropy\", \"gender\": \"binary_crossentropy\"},\n",
    "              loss_weights={\"age\": 0.25, \"income\": 1, \"gender\": 10})\n",
    "\n",
    "model.fit(posts,\n",
    "          [age_targets, income_group_targets, gender_targets],\n",
    "          epochs=10, batch_size=32)\n",
    "model.fit(posts,\n",
    "          {\"age\": age_targets, \"income\": income_group_targets, \"gender\": gender_targets},\n",
    "          epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InceptionV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.callbacks.ModelCheckpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 500), (25000, 500))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recreate model on imdb dataset to visualize whats happening during training\n",
    "max_features = 2000\n",
    "max_len = 500\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length=max_len, name=\"embed\"))\n",
    "model.add(layers.Conv1D(32, 7, activation=\"relu\"))\n",
    "model.add(layers.MaxPool1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation=\"relu\"))\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir my_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 63s 3ms/step - loss: 0.0103 - acc: 0.9985 - val_loss: 0.6140 - val_acc: 0.8592\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 70s 4ms/step - loss: 0.0059 - acc: 0.9992 - val_loss: 0.6848 - val_acc: 0.8590\n"
     ]
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir=\"my_log_dir\", histogram_freq=1, embeddings_freq=1\n",
    "    ), keras.callbacks.EarlyStopping(\n",
    "        patience=1)\n",
    "]\n",
    "\n",
    "history =  model.fit(X_train, y_train,\n",
    "                     batch_size=128,\n",
    "                     epochs=20,\n",
    "                     validation_split=0.2,\n",
    "                     callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
    "train_data.shape, train_labels.shape, test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.reshape((-1, 28, 28, 1)) / 255\n",
    "X_test = test_data.reshape((-1, 28, 28, 1)) / 255\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Conv network\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 29s 487us/step - loss: 0.1714 - acc: 0.9459\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 28s 468us/step - loss: 0.0477 - acc: 0.9852\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.0336 - acc: 0.9893\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 29s 478us/step - loss: 0.0243 - acc: 0.9927\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0201 - acc: 0.9943\n",
      "10000/10000 [==============================] - 2s 180us/step\n",
      "Test accuracy is: 99.18%\n"
     ]
    }
   ],
   "source": [
    "# Compile it\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=64)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy is: {:.2f}%\".format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "separable_conv2d_7 (Separabl (None, 26, 26, 32)        73        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_8 (Separabl (None, 11, 11, 64)        2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_9 (Separabl (None, 3, 3, 64)          4736      \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 44,787\n",
      "Trainable params: 44,787\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Conv network\n",
    "model = models.Sequential()\n",
    "model.add(layers.SeparableConv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.SeparableConv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.SeparableConv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 21s 347us/step - loss: 0.4237 - acc: 0.8693\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 20s 338us/step - loss: 0.1092 - acc: 0.9664\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 21s 344us/step - loss: 0.0723 - acc: 0.97722s - ETA: 0s - loss: 0.0721 - \n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 21s 342us/step - loss: 0.0573 - acc: 0.98200s - loss: 0.0572 - acc: 0.98\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 22s 371us/step - loss: 0.0485 - acc: 0.9847\n",
      "10000/10000 [==============================] - 2s 152us/step\n",
      "Test accuracy is: 98.11%\n"
     ]
    }
   ],
   "source": [
    "# Compile it\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=64)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy is: {:.2f}%\".format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-dbfe802327ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
